### 今天要删除一个数据超过千万的一个表，但是失败了。


#### 1.根据mysql文档了解到**InnoDB delete的时候有索引不会锁表**

[https://dev.mysql.com/doc/refman/5.6/en/innodb-locks-set.html](url)
> A locking read, an UPDATE, or a DELETE generally set record locks on every index record that is scanned in the processing of the SQL statement. It does not matter whether there are WHERE conditions in the statement that would exclude the row. InnoDB does not remember the exact WHERE condition, but only knows which index ranges were scanned. 

> 当delete 或者 update 语句执行的时候会创建一个行锁。
> 这个行锁不会根据你where条件排除行，InnoDB 不会记住你的where条件，只知道需要扫描的索引范围。

#### 2-1.所以我就查询了要删除的最大id（因为是要删除特定日期以前的数据）
    select max(id) from table where create_date < '2020-03-28 00:00:00';

#### 2-1.所以我就查询了要删除的最小id（因为是要删除特定日期以前的数据）
    select min(id) from table where create_date < '2020-03-28 00:00:00' order by id ASC limit 1;

#### 3.根据最大idh和最小id区间删除
    delete from table where id <= max_id and id >= min_id;

#### 3-1 查看索引的统计信息（确认索引的创建情况）
	show index from table；

#### 4.查看delete 语句执行的进程
    show processlist;

| Id  | User  | Host  |  db |  Command |  Time| State | info
|:----------|:----------|:----------|:----------|:----------|:----------|:----------|:----------
| 1   | db_user   | localhost  | db    | NULL    | 20   | updating  |Cell  delete from table where id <= max_id;   |

	如果state字段显示的是updating代表是正常的
    如果state字段显示的是query end 并持续很长时间则代表事务出现了问题

#### 5. 查看delete 语句执行的事务
        select trx_weight from information_schema.innodb_trx where trx_mysql_thread_id = 566708; 
	当trx_weight 接近0的时候 代表事务回滚成功 

#### 6. 分批次删除数据
    预估要查询的数据总数，然后分批次进行删除 
    100000 rows affected (12.43 sec)
    1000000 rows affected (4 min 25.29 sec)
    1000000 rows affected (4 min 33.30 sec)
    2000000 rows affected (10 min 20.78 sec)
    5000000 rows affected (35 min 8.08 sec) 
#### 7，以下是在mysql_5.6版本，一个表会大量插入，大量查询时进行删除操作时执行的。

#### 8. 
	mysql DB在第一次删除数据的情况下会根据索引删除数据
    如果紧接着进行第二次数据的删除不会走索引

### 后来发现这个表使用了mysql的分区表

#### 1.查看建表语句
    mysql> show create table table_name \G
    ************************** 1. row **************************
        Table: table_name
    Create Table: CREATE TABLE `table_name` (
    `id` int(11) NOT NULL AUTO_INCREMENT,
    `create_date` datetime NOT NULL,
    `update_date` datetime DEFAULT NULL,
    PRIMARY KEY (`id`,`create_date`),
    ) ENGINE=InnoDB AUTO_INCREMENT=233086472 DEFAULT CHARSET=utf8 
    /*!50100 PARTITION BY RANGE (YEAR(create_date))
    (PARTITION p2017 VALUES LESS THAN (2017) ENGINE = InnoDB,
    PARTITION p2018 VALUES LESS THAN (2018) ENGINE = InnoDB,
    PARTITION p2019 VALUES LESS THAN (2019) ENGINE = InnoDB,
    PARTITION p2020 VALUES LESS THAN (2020) ENGINE = InnoDB,
    PARTITION p2021 VALUES LESS THAN (2021) ENGINE = InnoDB,
    PARTITION p2022 VALUES LESS THAN (2022) ENGINE = InnoDB,
    PARTITION p2023 VALUES LESS THAN (2023) ENGINE = InnoDB,
    PARTITION p2024 VALUES LESS THAN (2024) ENGINE = InnoDB,
    PARTITION p2025 VALUES LESS THAN (2025) ENGINE = InnoDB,
    PARTITION p2026 VALUES LESS THAN (2026) ENGINE = InnoDB,
    PARTITION p2027 VALUES LESS THAN (2027) ENGINE = InnoDB,
    PARTITION p2028 VALUES LESS THAN (2028) ENGINE = InnoDB,
    PARTITION p2029 VALUES LESS THAN (2029) ENGINE = InnoDB,
    PARTITION p2030 VALUES LESS THAN (2030) ENGINE = InnoDB) */
    1 row in set (0.00 sec)

    根据sql数据不通的创建时间存入到不同的分区当中。
exmple：
| Id  | create_date  | date_date  | 
|:----------|:----------|:----------
| 1   | 2020:08:31 00:00:00   | 2020:08:31 00:00:00  | 

这条数据将会存入到`p2021`分区中

#### 2.删除分区
    假设这个分区有100w条数据，根据之前执行`delete from table where id <= max_id and id >= min_id;` 的方法
    删除这些user用户将会使用`1000000 rows affected (4 min 25.29 sec)` 时间

    使用删除分区表的方法
    ALTER TABLE t_user_push_log DROP PARTITION p2021;

    Connection id:    3960726
    Current database: db_cpon2
    Query OK, 0 rows affected (0.59 sec)

    使用0.59s删除完成了数据